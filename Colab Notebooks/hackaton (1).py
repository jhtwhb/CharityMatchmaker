# -*- coding: utf-8 -*-
"""hackaton.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F40A5TwZqYaz0W87SOiwlPXVa5tAw1Sf
"""

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.1.1-bin-hadoop2.7"

!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q http://apache.osuosl.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz
!tar xf spark-3.1.1-bin-hadoop2.7.tgz
!pip install -q findspark

import pyspark.sql.functions as func
from pyspark.sql.functions import length
import matplotlib
from matplotlib.pyplot import figure
import matplotlib.pyplot as plt
import numpy as np

import findspark
import string
findspark.init()
from pyspark.sql import SparkSession
from pyspark import SparkConf
from pyspark import SparkContext
from pyspark.sql import SQLContext
from pyspark import sql
from pyspark.streaming import StreamingContext

spark = SparkSession.builder.appName("hackaton").getOrCreate()

sc = spark.sparkContext

df = spark.read.option('header', True).csv('/content/drive/MyDrive/HackAThon2021/Data/Charity Navigator Scores Expenses Dataset/CLEAN_charity_data.csv') #reading csv into spark context

df.show(3) #show the top 3 row of the dataframe in spark

print('Num of rows in dataset: ' + str(df.count())) #output the total number of rows in the dataframe

state = df.filter(df.state == 'MO') #looks at charity only specific to a location 
state.show(3)
print('Total number of charities in [given state]: ' + str(state.count())) #outputs the number of rows for a given state 
print('\nAll categories in [given state]: ')
state.select('category').distinct().show() #only output distinct rows

df.groupBy('state').agg(func.count('state').alias('total')).show(20) #output the state of each charity, notice that there will be inaccurate data

result = df.groupBy('state').agg(func.count('state').alias('total')).sort(func.col('total').desc()).filter(length(df.state) == 2) #filter through the dataframe group each state and calculate the total num of rows for that state 
result.write.option("header", "true").csv("/content/drive/MyDrive/HackAThon2021/Data/states_and_numbers") #export this dataset that includes states and the total number of rows for each state

#using cleaned dataframe and the filtered dataframe that only includes the state and total rows for each state, plot a bar graph
numCharity = result.select('total').collect() 
state = result.select('state').collect()

numCharity = [int(row.total) for row in numCharity]
state = [row.state for row in state]

x = np.arange((len(state)))
width = 0.35

fig, ax = plt.subplots()
bar1 = ax.bar(x, numCharity, width, label = 'states')
ax.set_xticks(x)
ax.set_xticklabels(state)

plt.setp(ax.get_xticklabels(), rotation=90, horizontalalignment='right', fontsize='x-small')
plt.tight_layout()

df_clean = df.filter(length(df.state) == 2) #filter data to only include state characters == 2 
#output difference between filtered dataframe and original dataframe to see whether there is a difference in sizes 
print('Dataset with inaccurate data: ' + str(df.count())) 
print('Dataset with inaccurate data removed: ' + str(df_clean.count()))
#output the cleaned dataframe to a csv 
df_clean.write.option('header', 'true').csv('/content/drive/MyDrive/HackAThon2021/Data/CharityNav_Cleaned')

df_clean.groupBy(df_clean['state']).agg(func.avg('score').alias('average score')).sort(func.col('average score').desc()).show() #outputs the average scores for each state

df_keyword_search = df_clean.filter(df_clean['motto'].rlike('.*(save){1}.*')) #outputs the state that has a motto which includes the word 'save'
print(df_keyword_search.count())
df_keyword_search.show(5)